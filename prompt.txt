"import psycopg2
from faker import Faker
import random
import subprocess
import os

import os
import subprocess

print("Current working directory:", os.getcwd())

def run_sql_script(script_path, db_name, db_user, db_password, db_host="localhost"):
    env = os.environ.copy()
    env["PGPASSWORD"] = db_password

    cmd = [
        "psql",
        "-U", db_user,
        "-d", db_name,
        "-h", db_host,
        "-f", script_path
    ]
    
    print(f"Esecuzione di {script_path}...")
    subprocess.run(cmd, check=True, env=env)
    print(f"{script_path} completato.\n")

if __name__ == "__main__":
    # Parametri di connessione
    DB_NAME = "universita"      # Sostituisci con il nome del tuo database
    DB_USER = "postgres"      # Sostituisci se necessario
    DB_PASSWORD = "postgres"  # Sostituisci con la tua password
    DB_HOST = "localhost"
    
    # Percorsi dei file SQL (in questo esempio, nella directory corrente)
    create_tables_path = os.path.join(os.getcwd(), "create_tables.sql")
    create_indexes_btree_path = os.path.join(os.getcwd(), "create_indexes_btree.sql")
    create_indexes_hash_path = os.path.join(os.getcwd(), "create_indexes_hash.sql")

    # Per configurazione A (senza indice)
print("Configurazione A: Senza indice")
run_sql_script(create_tables_path, DB_NAME, DB_USER, DB_PASSWORD, DB_HOST)


# Parametri di connessione al database
DB_NAME = "universita"
DB_USER = "postgres"
DB_PASSWORD = "postgres"
DB_HOST = "localhost"  # o l'host appropriato

fake = Faker()

# Dimensioni dei dati
N_STUDENTI = 50000
N_CORSI = 5000
N_ISCRIZIONI = 2000000

# Connessione al database
conn = psycopg2.connect(dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, host=DB_HOST)
cur = conn.cursor()

# Svuota le tabelle (se esistono dati)
cur.execute("TRUNCATE TABLE Iscrizione CASCADE;")
cur.execute("TRUNCATE TABLE Corso CASCADE;")
cur.execute("TRUNCATE TABLE Studente CASCADE;")

# Popola la tabella Studente
for i in range(1, N_STUDENTI + 1):
    nome = fake.first_name()
    email = fake.email()
    indirizzo = fake.address().replace("\n", ", ")
    cur.execute(
        "INSERT INTO Studente (id, nome, email, indirizzo) VALUES (%s, %s, %s, %s);",
        (i, nome, email, indirizzo)
    )

# Popola la tabella Corso
for i in range(1, N_CORSI + 1):
    nome_corso = "Corso_" + fake.word()
    cfu = random.randint(3, 12)
    cur.execute(
        "INSERT INTO Corso (id, nome, cfu) VALUES (%s, %s, %s);",
        (i, nome_corso, cfu)
    )

# Popola la tabella Iscrizione
for _ in range(N_ISCRIZIONI):
    stud_id = random.randint(1, N_STUDENTI)
    corso_id = random.randint(1, N_CORSI)
    voto = random.randint(18, 30)
    cur.execute(
        "INSERT INTO Iscrizione (studente_id, corso_id, voto) VALUES (%s, %s, %s);",
        (stud_id, corso_id, voto)
    )

conn.commit()
cur.close()
conn.close()

print("Popolamento completato!")


import psycopg2
import time

# Parametri di connessione
DB_NAME = "universita"   # o "postgres", se il DB si chiama così
DB_USER = "postgres"
DB_PASSWORD = "postgres"
DB_HOST = "localhost"

queries = [
    {
        "name": "Query 1: join + selezione",
        "sql": """
            EXPLAIN ANALYZE
            SELECT s.nome, s.email, i.voto
            FROM Studente s
            JOIN Iscrizione i ON s.id = i.studente_id
            WHERE i.corso_id=10;
        """
    },
    {
        "name": "Query 2: range scan su corso_id",
        "sql": """
            EXPLAIN ANALYZE
            SELECT s.nome, s.email, i.voto
            FROM Studente s
            JOIN Iscrizione i ON s.id = i.studente_id
            WHERE i.corso_id BETWEEN 100 AND 200
            ORDER BY i.corso_id;
        """
    }
]

def get_stats(cur):
    """
    Recupera le statistiche correnti da pg_stat_database per il database DB_NAME.
    Ritorna una tupla: (numPin, numRead) dove:
      - numPin = blks_hit + blks_read (accessi totali ai blocchi)
      - numRead = blks_read (accessi fisici)
    """
    cur.execute("""
        SELECT blks_hit + blks_read, blks_read
        FROM pg_stat_database
        WHERE datname = %s;
    """, (DB_NAME,))
    return cur.fetchone()

def run_explain_analyze(connection, query_dict):
    """
    Esegue la EXPLAIN ANALYZE e ritorna l'output (lista di righe).
    """
    cur = connection.cursor()
    cur.execute(query_dict["sql"])
    rows = cur.fetchall()  # Ogni riga è una tupla con una singola colonna di testo
    cur.close()
    return rows

def run_query_with_stats(connection, query_dict):
    """
    Per la query indicata:
      - Recupera le statistiche I/O prima dell'esecuzione.
      - Esegue EXPLAIN ANALYZE e raccoglie il piano di esecuzione.
      - Attende un attimo per aggiornare le statistiche.
      - Recupera le statistiche I/O dopo l'esecuzione.
      - Calcola le differenze (differenza di numPin e numRead).
    Ritorna un dizionario con:
      - "name": nome della query
      - "plan": lista di righe del piano di esecuzione
      - "numPin_diff": differenza dei blocchi (hit+read)
      - "numRead_diff": differenza dei blocchi letti fisicamente
    """
    cur = connection.cursor()
    
    # Statistiche prima della query
    stats_before = get_stats(cur)
    
    # Esecuzione della query (EXPLAIN ANALYZE)
    plan_output = run_explain_analyze(connection, query_dict)
    
    connection.commit()
    time.sleep(2)  # Attesa per permettere l'aggiornamento delle statistiche
    
    # Statistiche dopo la query
    stats_after = get_stats(cur)
    cur.close()
    
    # Calcolo delle differenze
    numPin_diff = stats_after[0] - stats_before[0]
    numRead_diff = stats_after[1] - stats_before[1]
    
    return {
        "name": query_dict["name"],
        "plan": plan_output,
        "numPin_diff": numPin_diff,
        "numRead_diff": numRead_diff
    }

# Configurazione attuale: modifica a mano in base alla configurazione impostata ("NO_INDEX", "BTREE", "HASH")
config = "NO_INDEX"

# Apertura della connessione
# Apertura della connessione
conn = psycopg2.connect(dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, host=DB_HOST)
conn.autocommit = True

# Disabilita gli index scan per questa sessione
cur = conn.cursor()
cur.execute("SET enable_indexscan = off;")
cur.execute("SET enable_bitmapscan = off;")
#cur.execute("SET enable_hashjoin = off;")
cur.close()

print(f"==> Test PRE-ANALYZE ({config})")
results_pre = []
for q in queries:
    print(q["name"])
    result = run_query_with_stats(conn, q)
    # Stampa il piano di esecuzione
    print("Piano di esecuzione:")
    for line in result["plan"]:
        print(line[0])
    # Stampa le statistiche I/O
    print(f"  --> Differenza Num Pin: {result['numPin_diff']}, Differenza Num Read: {result['numRead_diff']}")
    print("-" * 60)
    results_pre.append(result)

print("==> Ora eseguo ANALYZE globale...")
cur = conn.cursor()
cur.execute("ANALYZE;")
cur.close()

print(f"==> Test POST-ANALYZE ({config})")
results_post = []
for q in queries:
    print(q["name"])
    result = run_query_with_stats(conn, q)
    print("Piano di esecuzione:")
    for line in result["plan"]:
        print(line[0])
    print(f"  --> Differenza Num Pin: {result['numPin_diff']}, Differenza Num Read: {result['numRead_diff']}")
    print("-" * 60)
    results_post.append(result)

conn.close()

# A questo punto, i dizionari 'results_pre' e 'results_post' contengono tutte le informazioni
# (piani di esecuzione e differenze nelle statistiche I/O) utili per l'analisi e la relazione.
" runanndolo h oottenuto ocme output:

==> Test PRE-ANALYZE (NO_INDEX)
Query 1: join + selezione
Piano di esecuzione:
Gather  (cost=2809.00..24076.90 rows=398 width=33) (actual time=14.685..97.349 rows=388 loops=1)
  Workers Planned: 2
  Workers Launched: 2
  ->  Hash Join  (cost=1809.00..23037.10 rows=166 width=33) (actual time=13.593..59.399 rows=129 loops=3)
        Hash Cond: (i.studente_id = s.id)
        ->  Parallel Seq Scan on iscrizione i  (cost=0.00..21227.67 rows=166 width=8) (actual time=0.501..46.195 rows=129 loops=3)
              Filter: (corso_id = 10)
              Rows Removed by Filter: 666537
        ->  Hash  (cost=1184.00..1184.00 rows=50000 width=33) (actual time=12.858..12.859 rows=50000 loops=3)
              Buckets: 65536  Batches: 1  Memory Usage: 3801kB
              ->  Seq Scan on studente s  (cost=0.00..1184.00 rows=50000 width=33) (actual time=0.211..5.982 rows=50000 loops=3)
Planning Time: 2.582 ms
Execution Time: 97.803 ms
  --> Differenza Num Pin: 6911, Differenza Num Read: 0
------------------------------------------------------------
Query 2: range scan su corso_id
Piano di esecuzione:
Gather Merge  (cost=27385.23..31428.01 rows=34650 width=37) (actual time=96.423..108.163 rows=40183 loops=1)
  Workers Planned: 2
  Workers Launched: 2
  ->  Sort  (cost=26385.21..26428.52 rows=17325 width=37) (actual time=67.736..68.991 rows=13394 loops=3)
        Sort Key: i.corso_id
        Sort Method: quicksort  Memory: 2152kB
        Worker 0:  Sort Method: quicksort  Memory: 981kB
        Worker 1:  Sort Method: quicksort  Memory: 976kB
        ->  Hash Join  (cost=1809.00..25165.48 rows=17325 width=37) (actual time=11.606..65.060 rows=13394 loops=3)
              Hash Cond: (i.studente_id = s.id)
              ->  Parallel Seq Scan on iscrizione i  (cost=0.00..23311.00 rows=17325 width=12) (actual time=0.014..48.099 rows=13394 loops=3)
                    Filter: ((corso_id >= 100) AND (corso_id <= 200))
                    Rows Removed by Filter: 653272
              ->  Hash  (cost=1184.00..1184.00 rows=50000 width=33) (actual time=11.425..11.426 rows=50000 loops=3)
                    Buckets: 65536  Batches: 1  Memory Usage: 3801kB
                    ->  Seq Scan on studente s  (cost=0.00..1184.00 rows=50000 width=33) (actual time=0.189..5.177 rows=50000 loops=3)
Planning Time: 0.138 ms
Execution Time: 109.966 ms
  --> Differenza Num Pin: 6929, Differenza Num Read: 0
------------------------------------------------------------
==> Ora eseguo ANALYZE globale...
==> Test POST-ANALYZE (NO_INDEX)
Query 1: join + selezione
Piano di esecuzione:
Gather  (cost=2809.00..24076.90 rows=398 width=33) (actual time=12.258..85.397 rows=388 loops=1)
  Workers Planned: 2
  Workers Launched: 2
  ->  Hash Join  (cost=1809.00..23037.10 rows=166 width=33) (actual time=12.179..49.095 rows=129 loops=3)
        Hash Cond: (i.studente_id = s.id)
        ->  Parallel Seq Scan on iscrizione i  (cost=0.00..21227.67 rows=166 width=8) (actual time=0.347..37.152 rows=129 loops=3)
              Filter: (corso_id = 10)
              Rows Removed by Filter: 666537
        ->  Hash  (cost=1184.00..1184.00 rows=50000 width=33) (actual time=11.602..11.602 rows=50000 loops=3)
              Buckets: 65536  Batches: 1  Memory Usage: 3801kB
              ->  Seq Scan on studente s  (cost=0.00..1184.00 rows=50000 width=33) (actual time=0.173..5.206 rows=50000 loops=3)
Planning Time: 0.163 ms
Execution Time: 85.803 ms
  --> Differenza Num Pin: 5968, Differenza Num Read: 0
------------------------------------------------------------
Query 2: range scan su corso_id
Piano di esecuzione:
Gather Merge  (cost=27392.29..31455.61 rows=34826 width=37) (actual time=90.233..102.322 rows=40183 loops=1)
  Workers Planned: 2
  Workers Launched: 2
  ->  Sort  (cost=26392.27..26435.80 rows=17413 width=37) (actual time=63.675..65.061 rows=13394 loops=3)
        Sort Key: i.corso_id
        Sort Method: quicksort  Memory: 2131kB
        Worker 0:  Sort Method: quicksort  Memory: 1021kB
        Worker 1:  Sort Method: quicksort  Memory: 956kB
        ->  Hash Join  (cost=1809.00..25165.71 rows=17413 width=37) (actual time=10.469..61.087 rows=13394 loops=3)
              Hash Cond: (i.studente_id = s.id)
              ->  Parallel Seq Scan on iscrizione i  (cost=0.00..23311.00 rows=17413 width=12) (actual time=0.012..45.186 rows=13394 loops=3)
                    Filter: ((corso_id >= 100) AND (corso_id <= 200))
                    Rows Removed by Filter: 653272
              ->  Hash  (cost=1184.00..1184.00 rows=50000 width=33) (actual time=10.297..10.297 rows=50000 loops=3)
                    Buckets: 65536  Batches: 1  Memory Usage: 3801kB
                    ->  Seq Scan on studente s  (cost=0.00..1184.00 rows=50000 width=33) (actual time=0.169..4.731 rows=50000 loops=3)
Planning Time: 0.122 ms
Execution Time: 103.961 ms
  --> Differenza Num Pin: 6974, Differenza Num Read: 0
------------------------------------------------------------




Puoi farmi la relazione del mio progetto??? sdtruttura del database, come l'ho fatto ocn che tencologie e che approccio e poi soppratutto una sezione dedicata a:

 il comportamento del sistema (in termini di piano di esecuzione delle interrogazioni), in presenza e assenza di indici e prima e dopo l’aggiornamento delle statistiche.

 QUESTO è IL CASO IN CUI NON HO ALCUN INDICE SU CORSO.ID!!!!! POI successivamente ti passerò l'output di queste 2 query nel caso in cui ho l'output
 per l 'indice b tree presente su tale cmapo, quindi ora nella relazione scrivi prima "cosa mi aspetterò e poi cos aho ottenuto"

